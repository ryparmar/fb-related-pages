\addcontentsline{toc}{chapter}{Závěr}
\chapter*{Závěr}
\label{chapter:zaver}
Každá společnost se musí potýkat s překážkami, které zároveň určují její další vývoj. Mezi největší současné výzvy patří klimatická změna. A přestože se o její existenci mezi odborníky diskutuje již několik let, mezi veřejností se jedná o téma, které způsobuje vysokou míru polarizace. Společnost je tak rozdělena na dva opoziční tábory, kterým se nedaří dosáhnout společného konsensu. A to i navzdory moderním informačním technologiím, které nám poskytují platformu k rovnocenné diskuzi a možnost spojit se s lidmi z celého světa. I přesto jsme od sebe navzájem v určitém smyslu mnohem izolovanější, než kdy předtím. 

Algoritmy filtrování, které nám pomáhají vyrovnat se s informačním zahlcením, jenž je tak typické pro moderní společnost, nám doporučují obsah, který je pro nás atraktivní. To nás uzavírá do filtračních bublin, kde se setkáváme stále se stejnými názory, jež nás kontinuálně utvrzují v našem již existujícím přesvědčení - což vede ještě k větší polarizaci. Naše přirozená lidská tendence tíhnout k tomu, co nám připadá správné, povědomé nebo známé pomáhá udržovat tuto propast mezi našimi a opozičními pohledy na jakoukoliv problematiku.  

To je obzvláště patrné na sociální síti Facebook, která se stala pro mnohé hlavním médiem pro komunikaci a konzumaci obsahu. Tato platforma se stala živnou půdou pro filtrační bubliny, dezinformace i fake news. Doporučovací algoritmus filtruje obsah na základě toho, co se uživatelům bude pravděpodobně líbit a s čím budou pravděpodobně interagovat. Nedokáže už však efektivně předcházet šíření obsahu, který může být pro uživatele potenciálně nebezpečný, nepravdivý a nebo porušuje zásady komunity, které si stanovuje samotný Facebook. Naopak takový obsah tento algoritmus ještě podporuje, neboť je atraktivní pro uživatele, kteří svou interakcí vyjadřují svůj zájem o tento druh příspěvku. 

Ve výzkumu, který byl uskutečněn v rámci této práce a jehož cílem bylo zjistit, zda facebookový algoritmus napomáhá prolamování filtračních bublin na facebookových stránkách, které se zabývají klimatickou změnou se ukázalo, že facebookový algoritmus selhává v účinném boji proti filtračním bublinám. Stránky, které mají pozitivní a negativní postoj ke klimatické změně v antropocentrickém pojetí, nejsou doporučovány uživatelům ekvivalentně - stránky \uv{pro} jsou oproti stránkám \uv{proti} doporučovány častěji.

Přestože častější prolamování stránek, které nesouhlasí s existencí klimatické změny (a často sdílí nepravdivý obsah) může být na jednu stranu vnímáno pozitivně, jako indicie, že se Facebook snaží zabránit šíření dezinformací (i když ne se stoprocentní úspěšností), z pohledu vzniku filtračních bublin to však až tak pozitivní znamení není. Facebookový algoritmus totiž podle všeho neumožňuje všem uživatelům dostat se k obsahu, který je vytvářen zastánci opačné ideologie, což může přispívat k zvětšování propasti mezi jednotlivými názorovými skupinami (menší toleranci a většímu vzájemnému nepochopení). To už ovšem otevírá spíše otázku etiky, svobody slova a práva na informace - neboli zda je omezování šíření fake news (nebo stránek, které je zveřejňují) služba veřejnosti nebo spíš cenzura. 

Nicméně tato práce i nadále dokazuje, že navzdory tvrzení Facebooku, je jeho fungování stále neprůhlednou černou skříňkou, která musí být podrobována dalšímu zkoumání. 

\setlength\parskip{5mm}
\begin{flushright}
   \textit{„Já ani nerozumím tomu, co myslí, když mluví o čestnosti. Myslí si, že je správné doporučovat lidem, aby se přidali k extremistickým skupinám podobným těm, které táhly na Kapitol? Jestliže všichni dostanou stejné doporučení znamená to, že je to fér?“}\footnote{Přeloženo z “I don’t even understand what they mean when they talk about fairness. Do they think it’s fair to recommend that people join extremist groups, like the ones that stormed the Capitol? If everyone gets the recommendation, does that mean it was fair?”} 
    
    - Ellery Roberts Biddle, šéfredaktor Ranking Digital Rights
    \end{flushright}
    

